Teoretycznie podstawy informatyki

13. Metody dowodzenia poprawnoÅ›ci algorytmÃ³w; niezmienniki:
	1.CzÄ™Å›ciowa poprawnoÅ›Ä‡ algorytymu oznacza,Â Å¼e jeÅ¼eli algorytm siÄ™ zakoÅ„czy, to zwrÃ³ci poprawny wynik
	2.WÅ‚asnoÅ›Ä‡ STOP algorytmu oznacza,Â Å¼e algorytm zakoÅ„czy swojÄ… pracÄ™ dla wszystkich poprawnych na wejÅ›ciu danych. 
	3.Algorytm jest caÅ‚kowicie poprawny, jeÅ¼eli ma obydwie wyÅ¼ej wymienione wÅ‚asnoÅ›ci.
	
	Metoda indukcji strukturalnej: JeÅ¼eli algorytm jest rekurencyjny, to udowadniamy poprawnoÅ›ci jego najmniejszego stanu (base case), nastepnie uznajemy, Å¼e dla n-tego kroku dziaÅ‚a poprawnie, a wiÄ™c pokazujemy, Å¼e dziaÅ‚a dla n+1 kroku ( dowolnego nastÄ™pnego.)
	
		
	Metoda niezmiennikÃ³w polega na znalezeniu takiego warunku logicznego A, ktÃ³ry jest:
		-Prawdziwy przed pierwszym wykonaniem ( inwariancja zaÅ‚oÅ¼eÅ„ wstÄ™pnych)
		-JeÅ¼eli warunek wykonania pÄ™tli jest prawdziwy, to A rÃ³wnieÅ¼ pozostaje prawdziwe.
		-Gdy warunek wykonania pÄ™tli staje siÄ™ faÅ‚szywy, to z prawdziwoÅ›ci A i negacji warunku wykonania pÄ™tli wynika post condition ( warunek koÅ„cowy)
		
		Dodatkowo, aby zagwarantowaÄ‡, Å¼e pÄ™tla rzeczywiÅ›cie siÄ™ zakoÅ„czy (poprawnoÅ›Ä‡ caÅ‚kowita), wprowadza siÄ™ zwykle **wariant**, czyli funkcjÄ™ ğ‘‰ stanu na liczbach naturalnych, ktÃ³ra maleje przy kaÅ¼dej iteracji i jest dolnie ograniczona przez 0.

	Ta metoda krok po kroku:
			1. sformulowanie pre i post condition
			2. Wymyslenie prostego do sprawdzenia niezmiennika, ktory laczy stan biezacy z obliczeniami algorytmu
			3. Pokaz ze na poczatku warunki sa spelnione
			4. Zaloz ze przed iteracja i po niej warunki sa prawdziwe, nastepnie pokaz ze w calym ciele petli nadal obowiazuje
			5. Dowiedz ze kiedy warunek przestaje byc prawdziwy - petla sie konczy osiagamy post condition
			przykÅ‚ad:
					S := 0
					i := 1
					while i â‰¤ n do
					    S := S + i
					    i := i + 1
					end while
			![[Pasted image 20250713181552.png]]


14.  Odwrotna Notacja Polska : definicja,wÅ‚asnoÅ›ci,zalety i wady, algorytmy.
		ONP notacja postfiksowa, ktÃ³ra jednoznacznie wyznacza kolejnoÅ›Ä‡ wykonywania dziaÅ‚aÅ„ i pozwala na caÅ‚kowitÄ…Â rezygnacjÄ™ z nawiasÃ³w.
		
		Zalety:
			+ UÅ‚atwia obliczenia komputerowe - wykorzystuje tylko stos
			+ Prosty algorytm konwersji zapisu infiksowego na ONP
		Wady:
			- Mniej czytelny dla czÅ‚owieka
			
		Algorytm obliczenia wartoÅ›ci z wyraÅ¼enia ONP:
			Dla wszystkich symboli z wyraÅ¼enia ONP wykonuj:
			jeÅ›li i-ty symbol jest liczbÄ…, to odÅ‚Ã³Å¼ go na stos,	
			jeÅ›li i-ty symbol jest operatorem (funkcjÄ…):	
			zdejmij ze stosu oczekiwanÄ… liczbÄ™ elementÃ³w (parametrÃ³w)
			odÅ‚Ã³Å¼ na stos wynik dziaÅ‚ania operatora (wynik funkcji)
			Zdejmij ze stosu wynik.

15. Â Modele obliczeÅ„: maszyna Turinga, automat skoÅ„czony, automat ze stosem.
		Maszyna Turinga jest w stanie obsÅ‚uÅ¼yÄ‡ dowolny jÄ™zyk rekurencyjnie przeliczalny.
		
		![[Pasted image 20250713185456.png]]

		![[Pasted image 20250713185700.png]]

		Warto wspomnieÄ‡, Å¼e kaÅ¼dy jÄ™zyk skoÅ„czony jest ackeptowany przez pewien deterministyczny automat skoÅ„czony.

		![[Pasted image 20250713185801.png]]
 16. ZÅ‚oÅ¼onoÅ›Ä‡ obliczeniowa - definicja notacji: O,â„¦,Î˜
	 Big O - notacja O, to gÃ³rne ogranicznenie potÄ™gi przy wiodÄ…cym wyrazie okreÅ›lajÄ…cym zÅ‚oÅ¼onoÅ›Ä‡ algorytmu.
	 â„¦ - notacja okreÅ›lajÄ…ca dolne ograniczenie okreÅ›lajÄ…ce zÅ‚oÅ¼onoÅ›Ä‡ obliczeniowÄ… algorytmu w najlepszym przypadku.
	 Î˜- notacja rÃ³wna - jest to Å›cisÅ‚e ograniczenie okreÅ›lajÄ…ce zÅ‚oÅ¼onoÅ›Ä‡ olbiczeniowÄ… algorytmu, wiÄ™ksze niÅ¼ omega, mniejsze niÅ¼ big O.
	 PrzykÅ‚ad:
			 3n^2â‰¤3n^2+5n+10â‰¤4n^2
			 â„¦        â‰¤    Î˜              â‰¤  O
			 ![[Pasted image 20250713210420.png]]


17. Lista, kolejka i kolejka priorytetowa: ujÄ™cie abstrakcyjne, moÅ¼liwe implementacje i zÅ‚oÅ¼onoÅ›ci:

	Lista to abstrakcyjny typ danych, ktÃ³ra przechowuje elementy tego samego typu danych, wykorzystuje pamiÄ™Ä‡ w sposÃ³b dynamiczny lub statyczny, zapewnia sekwencyjny dostÄ™p danych, ktÃ³re sÄ… liniowo uporzÄ…dkowane.
	WyrÃ³Å¼niamy listÄ™ w postaci:
		Tablicowej - ArrayList, wykorzystujÄ…ce pamiÄ™Ä‡ w sposÃ³b statyczny oraz ma z gÃ³ry okreÅ›lony rozmiar, ktÃ³ry moÅ¼e byÄ‡ niewykorzystany podczas jej istnienia.
		WiÄ…zanej - LinkedList, moÅ¼e byÄ‡ jedno lub dwu kierunkowa, a nawet cykliczna, pierwszy element nazywany gÅ‚owÄ… listy zawiera wskaÅºnik na drugi element, ktÃ³ry zawiera wskaÅºnik na trzeci itd... ostatni element nazywamy ogonem - tail

	Opearcje na listach i ich zÅ‚oÅ¼onoÅ›Ä‡:
		Create - staÅ‚y
		Append- staÅ‚y
		Insert - czas liniowy
		Find - czas liniowy
		Delete - czas liniowy
		Makenull - staÅ‚y


	Kolejka- ADT, ktÃ³ry jest sekwencyjny i dziaÅ‚a na bazie FIFO, dodajemy nowy element na koniec kolejki, usuwamy element z przodu kolejki.
	Kolejka zawiera informacje o pierwszym elemencie - front i rear - ostatnim, moÅ¼e byÄ‡ przechowywana w formie indeksu np.
	
	WyrÃ³Å¼niamy dwa typy kolejek - TablicÄ™ cyklicznÄ… i ListÄ™ wiÄ…zanÄ…
	
	Operacje na kolejkach:
		Create - Tworzy pusta kolejke, const time
		isEmpty - zwraca informacje, czy kolejka jest pusta, const time
		Enqueue(x) - wstawia x do kolejki - const time
		 Front - odczytuje pierwszy element z kolejki, const time
		 dequeue- usuwa pierwszy element z kolejki i go zwraca, const time

	Implementacja kolejki:
		Na poczÄ…tku zauwaÅ¼my, Å¼e nieefektywnÄ… realizacjÄ… kolejki w tablicy jest przyjÄ™cie,
		Å¼e poczÄ…tek kolejki front bÄ™dzie zawsze rÃ³wny 0, a rear bÄ™dzie indeksem do pierw-
		szego wolnego elementu tablicy.

	 .       Najbardziej efektywnym rozwiÄ…zaniem jest reprezentacja kolejki w tablicy cy
		klicznej. Operacje wstawiania i usuwania zwiÄ™kszajÄ… pozycje koÅ„ca i poczÄ…tku ko-
		lejki o 1 modulo rozmiar tablicy,


	Kolejka priorytetowa to ADT, ktÃ³rego celem jest usuwanie obiektu priorytetu najwiÄ™kszego/najmniejszego, w zaleÅ¼noÅ›ci od implementacji
		Jej implementacja opiera siÄ™ o tzw. MIN/MAX Heap, polega na implementacji drzewa binarnego na sorted arrayu. Zachowuje staÅ‚Ä… kolejnoÅ›Ä‡ poprzez insercje na koniec i sprawdzenie poprawnoÅ›ci stanu - nowy element zostanie "wybÄ…belkowany" do gÃ³ry poprzez zamianÄ™ odpowiednich indeksÃ³w w tablicy.



18. Algorytmy sortowania - quicksort, mergesort, porÃ³wnanie, zÅ‚oÅ¼onoÅ›Ä‡, algorytmy sortowania bez porÃ³wnaÅ„: zliczanie, kubeÅ‚kowe, pozycyjne.
	Implementacja quicksorta :

	![[Pasted image 20250714110913.png]]
	Quicksort jest jednym z najpopularniejszych algorytmÃ³w sortowania, opiera siÄ™ o podejÅ›cie divide and conquer, czyli rozbijania problemu na coraz mniejsze podproblemy w celu wykonania na nich operacji stanu bazowego

	Quicksort ma zÅ‚oÅ¼onoÅ›Ä‡ Å›redniÄ… i optymistycznÄ… nlogn, oraz zÅ‚oÅ¼onosc n^2 w najgorszym przypadku.

	Mergesort:
	![[Pasted image 20250714111213.png]]

	Mergesort - zÅ‚oÅ¼onoÅ›Ä‡ optymistyczna, Å›rednia i pesymistyczna = nlogn
	Pomimo lepszej zÅ‚oÅ¼onoÅ›ci teoretycznej quicksort jest czÄ™sto szybszy, ze wzgledu na dobrÄ… zÅ‚oÅ¼onoÅ›Ä‡ pamiÄ™ciowÄ… i cacheowanie wykorzystywane przez system.
	![[Pasted image 20250714111418.png]]

### Sortowanie przez zliczanie

Sortowanie przez zliczanie to algorytm stabilny o zÅ‚oÅ¼onoÅ›ci O(n + k), gdzie n to liczba elementÃ³w, a k to maksymalna wartoÅ›Ä‡ klucza. DziaÅ‚a nastÄ™pujÄ…co:
1. Tworzy siÄ™ tablicÄ™ pomocniczÄ… C rozmiaru k+1 i zlicza, ile razy kaÅ¼dy klucz wystÄ™puje w wejÅ›ciowej tablicy A.  
2. PrzeksztaÅ‚ca siÄ™ C tak, by C[j] zawieraÅ‚o liczbÄ™ elementÃ³w â‰¤ j.  
3. Przechodzi siÄ™ przez tablicÄ™ A od koÅ„ca do poczÄ…tku i umieszcza kaÅ¼dy element A[i] na wÅ‚aÅ›ciwej pozycji w wyjÅ›ciowej tablicy B, dekrementujÄ…c odpowiedniÄ… wartoÅ›Ä‡ w C.  
DziÄ™ki temu elementy o rÃ³wnych kluczach zachowujÄ… wzglÄ™dny porzÄ…dek (stabilnoÅ›Ä‡), a caÅ‚oÅ›Ä‡ wykonuje siÄ™ w czasie liniowym wzglÄ™dem n i k.


```pseudocode
COUNTING_SORT(A, k):
    # A[1..n], wartoÅ›ci w [0..k]
    let C[0..k] byÄ‡ nowÄ… tablicÄ…
    for j from 0 to k:
        C[j] â† 0
    for i from 1 to length(A):
        C[A[i]] â† C[A[i]] + 1
    for j from 1 to k:
        C[j] â† C[j] + C[jâˆ’1]
    let B[1..length(A)] byÄ‡ nowÄ… tablicÄ…
    for i from length(A) down to 1:
        B[C[A[i]]] â† A[i]
        C[A[i]] â† C[A[i]] âˆ’ 1
    return B

```


Sortowanie kubeÅ‚kowe to algorytm o oczekiwanej zÅ‚oÅ¼onoÅ›ci O(n + m), gdzie n to liczba elementÃ³w, a m â€“ liczba kubeÅ‚kÃ³w. ZakÅ‚ada siÄ™ rÃ³wnomierny rozkÅ‚ad danych (np. wartoÅ›ci z przedziaÅ‚u [0,1)). DziaÅ‚a nastÄ™pujÄ…co:
1. Tworzy siÄ™ n pustych kubeÅ‚kÃ³w (list), do ktÃ³rych rozdziela siÄ™ elementy wejÅ›ciowej tablicy A na podstawie funkcji indeksujÄ…cej (np. floor(nÂ·A[i])).  
2. KaÅ¼dy kubeÅ‚ek sortuje siÄ™ wewnÄ™trznie (najczÄ™Å›ciej sortowaniem przez wstawianie â€” INSERTION_SORT).  
3. ZawartoÅ›Ä‡ wszystkich kubeÅ‚kÃ³w konkatenacja w kolejnoÅ›ci od najmniejszego do najwiÄ™kszego daje wynik posortowany.  
Algorytm jest bardzo wydajny, gdy dane majÄ… rÃ³wny rozkÅ‚ad i gdy wewnÄ™trzne sortowanie kubeÅ‚kÃ³w jest szybkie.

```
Sortowanie kubeÅ‚kowe
BUCKET_SORT(A):
    # A[1..n], wartoÅ›ci w [0,1)
    let B[0..nâˆ’1] byÄ‡ n pustymi kubeÅ‚kami (listami)
    for i from 1 to n:
        index â† floor(n * A[i])
        B[index].append(A[i])
    for each bucket in B:
        INSERTION_SORT(bucket)
    return concatenation of all buckets w kolejnoÅ›ci
```

Sortowanie kubeÅ‚kowe to algorytm o oczekiwanej zÅ‚oÅ¼onoÅ›ci O(n + m), gdzie n to liczba elementÃ³w, a m â€“ liczba kubeÅ‚kÃ³w. ZakÅ‚ada siÄ™ rÃ³wnomierny rozkÅ‚ad danych (np. wartoÅ›ci z przedziaÅ‚u [0,1)). DziaÅ‚a nastÄ™pujÄ…co:
1. Tworzy siÄ™ n pustych kubeÅ‚kÃ³w (list), do ktÃ³rych rozdziela siÄ™ elementy wejÅ›ciowej tablicy A na podstawie funkcji indeksujÄ…cej (np. floor(nÂ·A[i])).  
2. KaÅ¼dy kubeÅ‚ek sortuje siÄ™ wewnÄ™trznie (najczÄ™Å›ciej sortowaniem przez wstawianie â€” INSERTION_SORT).  
3. ZawartoÅ›Ä‡ wszystkich kubeÅ‚kÃ³w konkatenacja w kolejnoÅ›ci od najmniejszego do najwiÄ™kszego daje wynik posortowany.  
Algorytm jest bardzo wydajny, gdy dane majÄ… rÃ³wny rozkÅ‚ad i gdy wewnÄ™trzne sortowanie kubeÅ‚kÃ³w jest szybkie.


RADIX sort- sortowanie pozycyjne
```
RADIX_SORT(A, d, b):
    # A[1..n], kaÅ¼dy element ma d cyfr w bazie b
    for i from 1 to d:
        A â† STABLE_COUNTING_SORT_BY_DIGIT(A, i, b)
    return A

STABLE_COUNTING_SORT_BY_DIGIT(A, i, b):
    let C[0..bâˆ’1] â† 0
    for each x in A:
        digit â† floor(x / b^(iâˆ’1)) mod b
        C[digit] â† C[digit] + 1
    for j from 1 to bâˆ’1:
        C[j] â† C[j] + C[jâˆ’1]
    let B[1..length(A)]
    for j from length(A) down to 1:
        digit â† floor(A[j] / b^(iâˆ’1)) mod b
        B[C[digit]] â† A[j]
        C[digit] â† C[digit] âˆ’ 1
    return B
```

Sortowanie pozycyjne to metoda stabilnego sortowania kluczy wielocyfrowych (liczb, Å‚aÅ„cuchÃ³w znakÃ³w) w czasie O(dÂ·(n + b)), gdzie d to liczba cyfr (pozycji), a b â€“ baza. DziaÅ‚a wedÅ‚ug schematu LSD (Least Significant Digit) lub MSD:
1. Dla kaÅ¼dej pozycji i od najmniej znaczÄ…cej (i=1) do najbardziej znaczÄ…cej (i=d):  
   - Wykonuje siÄ™ stabilne sortowanie (zwykle COUNTING_SORT) wedÅ‚ug wartoÅ›ci cyfry na pozycji i.  
   - DziÄ™ki stabilnoÅ›ci wczeÅ›niejsze porzÄ…dki wg niÅ¼szych pozycji sÄ… zachowane.  
2. Po d krokach otrzymujemy w peÅ‚ni posortowanÄ… tablicÄ™.  
Radix Sort jest szczegÃ³lnie efektywny, gdy d i b sÄ… niewielkie w porÃ³wnaniu do n, i pozwala ominÄ…Ä‡ logarytmiczny czynnik charakterystyczny dla porÃ³wnaÅ„.  



19.Drzewa BST, porzÄ…dki przeglÄ…dania, wyszukiwanie poprzednika i nastÄ™pnika, usuwanie wÄ™zÅ‚a. Drzewa zrÃ³wnowaÅ¼one, AVL, podstawowe operacje i ich zÅ‚oÅ¼onoÅ›Ä‡.

# Drzewa BST

BST czyli binary search tree to takie drzewo, ktore zchowuje strukturÄ™ uporzÄ…dkowanÄ…, takie, Å¼e:
L>N>R, gdzie L to lewe poddrzewo N to wartoÅ›Ä‡ wÄ™zÅ‚a, a R to prawe poddrzewo.

## 1. PorzÄ…dki przeglÄ…dania
- **Preorder (N L R)**  
  1. OdwiedÅº bieÅ¼Ä…cy wÄ™zeÅ‚  
  2. PrzetwÃ³rz lewe poddrzewo  
  3. PrzetwÃ³rz prawe poddrzewo  
- **Inorder (L N R)**  
  1. PrzetwÃ³rz lewe poddrzewo  
  2. OdwiedÅº bieÅ¼Ä…cy wÄ™zeÅ‚  
  3. PrzetwÃ³rz prawe poddrzewo  
  > Daje posortowany ciÄ…g kluczy.  
- **Postorder (L R N)**  
  1. PrzetwÃ³rz lewe poddrzewo  
  2. PrzetwÃ³rz prawe poddrzewo  
  3. OdwiedÅº bieÅ¼Ä…cy wÄ™zeÅ‚  

## 2. Wyszukiwanie poprzednika i nastÄ™pnika
- **Poprzednik (predecessor)**  
  1. JeÅ›li wÄ™zeÅ‚ ma lewe poddrzewo â†’ najwiÄ™kszy element w tym poddrzewie  
  2. Inaczej â†’ wspinaj siÄ™ w gÃ³rÄ™, aÅ¼ wejdziesz wÄ™zeÅ‚ bÄ™dÄ…cy **prawym** dzieckiem swojego rodzica; ten rodzic to poprzednik  
- **NastÄ™pnik (successor)**  
  1. JeÅ›li wÄ™zeÅ‚ ma prawe poddrzewo â†’ najmniejszy element w tym poddrzewie  
  2. Inaczej â†’ wspinaj siÄ™ w gÃ³rÄ™, aÅ¼ wejdziesz wÄ™zeÅ‚ bÄ™dÄ…cy **lewym** dzieckiem swojego rodzica; ten rodzic to nastÄ™pnik  

## 3. Usuwanie wÄ™zÅ‚a
- **Przypadki**  
  1. **LiÅ›Ä‡** â†’ usuÅ„ wÄ™zeÅ‚  
  2. **Jedno dziecko** â†’ zastÄ…p wÄ™zeÅ‚ swoim dzieckiem  
  3. **Dwoje dzieci** â†’ znajdÅº nastÄ™pnika (lub poprzednika), skopiuj jego wartoÅ›Ä‡ do usuwanego wÄ™zÅ‚a, a nastÄ™pnie usuÅ„ tego nastÄ™pnika (ma co najwyÅ¼ej jedno dziecko)  
- **ZÅ‚oÅ¼onoÅ›Ä‡**: O(h), gdzie h to wysokoÅ›Ä‡ drzewa  
  - W najgorszym przypadku BST: O(n)  
  - Dla drzewa zrÃ³wnowaÅ¼onego: O(log n)  

---

# Drzewa zrÃ³wnowaÅ¼one

## 1. Drzewa AVL
- **Warunek rÃ³wnowagi**: dla kaÅ¼dego wÄ™zÅ‚a rÃ³Å¼nica wysokoÅ›ci lewego i prawego poddrzewa â‰¤ 1  
- **Operacje**  
  - **Wyszukiwanie**: jak w BST (O(log n))  
  - **Wstawianie**:  
    1. Wstaw jak w BST  
    2. CofajÄ…c siÄ™ w gÃ³rÄ™, aktualizuj wysokoÅ›ci i w razie potrzeby wykonaj rotacje  
  - **Usuwanie**:  
    1. UsuÅ„ jak w BST  
    2. CofajÄ…c siÄ™ w gÃ³rÄ™, aktualizuj wysokoÅ›ci i przywrÃ³Ä‡ rÃ³wnowagÄ™ przez rotacje  
- **Rotacje**  
  - **Pojedyncza** (LL, RR)  
  - **PodwÃ³jna** (LR, RL)  
- **ZÅ‚oÅ¼onoÅ›Ä‡**: O(log n) dla wszystkich podstawowych operacji  

## 2. B-drzewa (rzÄ…d m)
- **Struktura**  
  - KaÅ¼dy wÄ™zeÅ‚ (poza korzeniem) ma od âŒˆm/2âŒ‰ do m dzieci  
  - Kluczy w wÄ™Åºle jest o 1 mniej niÅ¼ dzieci (od âŒˆm/2âŒ‰âˆ’1 do mâˆ’1)  
- **Operacje**  
  - **Wyszukiwanie**: przeglÄ…danie kluczy w wÄ™Åºle + rekurencja do wÅ‚aÅ›ciwego poddrzewa (O(log n))  
  - **Wstawianie**:  
    1. Wstaw klucz do liÅ›cia  
    2. JeÅ›li liczba kluczy > mâˆ’1 â†’ split wÄ™zÅ‚a: mediana idzie do rodzica, pozostaÅ‚e poÅ‚Ã³wki tworzÄ… dwa wÄ™zÅ‚y  
    3. Rekurencyjnie naprawiaj ewentualne przepeÅ‚nienia w gÃ³rÄ™  
  - **Usuwanie**:  
    1. UsuÅ„ klucz z wÄ™zÅ‚a (liÅ›cia lub wewnÄ™trznego, zastÄ™pujÄ…c go nastÄ™pnikiem/poprzednikiem)  
    2. JeÅ›li liczba kluczy < âŒˆm/2âŒ‰âˆ’1 â†’ wypoÅ¼ycz klucz od sÄ…siada (rotacja) lub poÅ‚Ä…cz wÄ™zÅ‚y (merge) i zaktualizuj rodzica  
- **ZÅ‚oÅ¼onoÅ›Ä‡**: O(log n) dla wyszukiwania, wstawiania i usuwania  


## 20. Sposoby konstrukcji algorytmÃ³w

### 1. Metoda "dziel i zwyciÄ™Å¼aj"
- **Idea**: problem dzielimy na mniejsze podproblemy, rozwiÄ…zujemy je niezaleÅ¼nie, a nastÄ™pnie Å‚Ä…czymy wyniki.  
- **PrzykÅ‚ady**: sortowanie szybkiego (QuickSort), sortowanie przez scalanie (MergeSort), wyszukiwanie binarne.  
- **Zalety**:  
  - czÄ™sto prostsza rekurencyjna implementacja  
  - dobre wykorzystanie wielordzeniowoÅ›ci (podproblemy moÅ¼na rozwiÄ…zywaÄ‡ rÃ³wnolegle)  
  - zÅ‚oÅ¼onoÅ›Ä‡ czÄ™sto O(n log n) lub lepsza  
- **Wady**:  
  - narzut pamiÄ™ciowy na rekurencjÄ™ i dodatkowe struktury (np. bufor scalania)  
  - trudne problemy, w ktÃ³rych podproblemy siÄ™ nakÅ‚adajÄ… â€“ moÅ¼e prowadziÄ‡ do nadmiarowych obliczeÅ„  

### 2. Programowanie dynamiczne
- **Idea**: podproblemy nakÅ‚adajÄ… siÄ™; zapisujemy ich wyniki (memoizacja/tablica) i uÅ¼ywamy ponownie zamiast ponownie obliczaÄ‡.  
- **PrzykÅ‚ady**: obliczanie ciÄ…gu Fibonacciego (z zapamiÄ™tywaniem), problem plecakowy (0/1 Knapsack), problem najdÅ‚uÅ¼szego wspÃ³lnego podciÄ…gu (LCS).  
- **Zalety**:  
  - eliminuje powtarzajÄ…ce siÄ™ obliczenia â†’ znaczÄ…ce przyspieszenie  
  - czÄ™sto zamienia zÅ‚oÅ¼onoÅ›Ä‡ wykÅ‚adniczÄ… na wielomianowÄ…  
- **Wady**:  
  - wymaga dodatkowej pamiÄ™ci na tablice/memoizacjÄ™  
  - moÅ¼e byÄ‡ trudne do sformuÅ‚owania stanu i przejÅ›Ä‡ rekurencyjnych  

### 3. PorÃ³wnanie
- **NakÅ‚ad obliczeniowy**:  
  - *Dzielenie i zwyciÄ™Å¼aj*: czas czÄ™sto O(n log n), ale moÅ¼e powtarzaÄ‡ obliczenia, jeÅ›li podproblemy siÄ™ nakÅ‚adajÄ…  
  - *Dynamiczne*: zazwyczaj O(nÂ·m) dla problemÃ³w z dwoma parametrami, bez nadmiarowych obliczeÅ„  
- **PamiÄ™Ä‡**:  
  - *Dz.i.z.*: niÅ¼sze potrzeby, poza rekurencjÄ… i ewentualnymi strukturami pomocniczymi  
  - *DP*: wiÄ™ksze potrzeby na przechowywanie tablic i wynikÃ³w  
- **ÅatwoÅ›Ä‡ rÃ³wnoleglenia**:  
  - *Dz.i.z.*: dobra (podproblemy niezaleÅ¼ne)  
  - *DP*: trudniejsza (zaleÅ¼noÅ›ci miÄ™dzy stanami)  

---

## Algorytm zachÅ‚anny

### PrzykÅ‚ad optymalnego wykorzystania
- **Problem wydawania reszty z monet (monetarny system kanoniczny)**  
  - Dla waluty o nominaÅ‚ach np. [1, 2, 5, 10, 20, 50] algorytm zachÅ‚anny (zawsze wziÄ…Ä‡ najwiÄ™kszy moÅ¼liwy nominaÅ‚) daje zawsze minimalnÄ… liczbÄ™ monet.  

### PrzykÅ‚ad nieoptymalnego wykorzystania
- **Problem wydawania reszty â€“ nietypowy zestaw nominaÅ‚Ã³w**  
  - Dla nominaÅ‚Ã³w [1, 3, 4] i reszty 6 algorytm zachÅ‚anny wybierze 4 + 1 + 1 = 3 monety, podczas gdy optymalnie 3 + 3 = 2 monety.  

- **Problem plecakowy 0/1**  
  - ZachÅ‚anne dobieranie przedmiotÃ³w wedÅ‚ug najwyÅ¼szej wartoÅ›ci na jednostkÄ™ ciÄ™Å¼aru (v/w) nie gwarantuje optymalnego wypeÅ‚nienia plecaka â€“ naleÅ¼y uÅ¼yÄ‡ programowania dynamicznego.  

21. Algorytmy Grafowe
## 21.Algorytmy grafowe

---

### 1. Przeszukiwanie wszerz (BFS)

**Opis:**  
Przeszukiwanie wszerz eksploruje graf warstwami, zaczynajÄ…c od wierzchoÅ‚ka ÅºrÃ³dÅ‚owego. Najpierw odwiedza wszystkie wierzchoÅ‚ki odlegÅ‚e o 1 krawÄ™dÅº, potem o 2, itd. Przydatne do wyznaczania najkrÃ³tszych Å›cieÅ¼ek w grafie niewaÅ¼onym.

**ZÅ‚oÅ¼onoÅ›Ä‡:**  
- Czasowa: O(V + E)  
- PamiÄ™ciowa: O(V)

```pseudocode
BFS(G, s):
    for each u in G.V:
        u.color â† WHITE; u.d â† âˆ; u.Ï€ â† NIL
    s.color â† GRAY; s.d â† 0; s.Ï€ â† NIL
    Q â† empty queue
    ENQUEUE(Q, s)
    while Q â‰  âˆ…:
        u â† DEQUEUE(Q)
        for each v in G.adj[u]:
            if v.color = WHITE:
                v.color â† GRAY
                v.d â† u.d + 1
                v.Ï€ â† u
                ENQUEUE(Q, v)
        u.color â† BLACK
```
##2. Przeszukiwanie wgÅ‚Ä…b(DFS)
```
DFS(G):
    for each u in G.V:
        u.color â† WHITE; u.Ï€ â† NIL
    time â† 0
    for each u in G.V:
        if u.color = WHITE:
            DFS-Visit(G, u)

DFS-Visit(G, u):
    time â† time + 1; u.d â† time; u.color â† GRAY
    for each v in G.adj[u]:
        if v.color = WHITE:
            v.Ï€ â† u
            DFS-Visit(G, v)
    u.color â† BLACK
    time â† time + 1; u.f â† time
```


## Dijkstra

**Opis:** Znajduje najkrÃ³tsze Å›cieÅ¼ki od jednego ÅºrÃ³dÅ‚a w grafie z nieujemnymi wagami.  
**ZÅ‚oÅ¼onoÅ›Ä‡ czasowa:**

- z kopcem binarnym: O((V + E) log V)
    
- z kopcem Fibonacciego: O(V log V + E)  
    **ZÅ‚oÅ¼onoÅ›Ä‡ pamiÄ™ciowa:** O(V)
```
DIJKSTRA(G, s):
    for each u in G.V:
        u.d â† âˆ
        u.Ï€ â† NIL
    s.d â† 0
    Q â† G.V               # min-kopiec wedÅ‚ug u.d
    while Q â‰  âˆ… do
        u â† EXTRACT-MIN(Q)
        for each v in G.adj[u] do
            if v.d > u.d + w(u,v) then
                v.d â† u.d + w(u,v)
                v.Ï€ â† u
                DECREASE-KEY(Q, v)
```

## Bellmanâ€“Ford

**Opis:** Znajduje najkrÃ³tsze Å›cieÅ¼ki od jednego ÅºrÃ³dÅ‚a nawet przy ujemnych wagach (bez ujemnych cykli).  
**ZÅ‚oÅ¼onoÅ›Ä‡ czasowa:** O(VÂ·E)  
**ZÅ‚oÅ¼onoÅ›Ä‡ pamiÄ™ciowa:** O(V)
```
BELLMAN-FORD(G, s):
    for each u in G.V:
        u.d â† âˆ
        u.Ï€ â† NIL
    s.d â† 0
    for i from 1 to |G.V|âˆ’1 do
        for each (u, v) in G.E do
            if v.d > u.d + w(u,v) then
                v.d â† u.d + w(u,v)
                v.Ï€ â† u
    # opcjonalnie detekcja ujemnego cyklu:
    for each (u, v) in G.E do
        if v.d > u.d + w(u,v) then
            report "ujemny cykl"

```


## BorÅ¯vka

**Opis:** Buduje MST przez wielokrotne Å‚Ä…czenie najmniejszych krawÄ™dzi z kaÅ¼dego komponentu.  
**ZÅ‚oÅ¼onoÅ›Ä‡ czasowa:** O(E log V)  
**ZÅ‚oÅ¼onoÅ›Ä‡ pamiÄ™ciowa:** O(V)

pseudocode

```
BORUVKA(G):
    A â† âˆ…
    make each vertex its own component
    while number_of_components > 1 do
        E' â† âˆ…
        for each component C do
            find lightest edge (u,v) with u in C, v not in C
            E'.append((u,v))
        for each (u,v) in E' do
            if FIND-SET(u) â‰  FIND-SET(v) then
                A.append((u,v))
                UNION(u, v)
    return A

```

## Prim

**Opis:** Rozpoczyna od jednego wierzchoÅ‚ka, iteracyjnie doÅ‚Ä…cza najtaÅ„szÄ… krawÄ™dÅº Å‚Ä…czÄ…cÄ… drzewo z resztÄ… grafu.  
**ZÅ‚oÅ¼onoÅ›Ä‡ czasowa:**

- z kopcem binarnym: O((V + E) log V)
    
- z kolejkÄ… priorytetowÄ… Diala lub bajtowym kopcem: O(E + V log V)  
    **ZÅ‚oÅ¼onoÅ›Ä‡ pamiÄ™ciowa:** O(V)

```
PRIM(G, r):
    for each u in G.V:
        u.key â† âˆ
        u.Ï€ â† NIL
    r.key â† 0
    Q â† G.V               # min-kopiec wedÅ‚ug u.key
    while Q â‰  âˆ… do
        u â† EXTRACT-MIN(Q)
        for each v in G.adj[u] do
            if v in Q and w(u,v) < v.key then
                v.Ï€ â† u
                v.key â† w(u,v)
                DECREASE-KEY(Q, v)
```

## Kruskal

**Opis:** Sortuje krawÄ™dzie rosnÄ…co i dodaje je, jeÅ›li Å‚Ä…czÄ… rÃ³Å¼ne komponenty (DSU).  
**ZÅ‚oÅ¼onoÅ›Ä‡ czasowa:** O(E log E) = O(E log V)  
**ZÅ‚oÅ¼onoÅ›Ä‡ pamiÄ™ciowa:** O(V)

pseudocode

```
KRUSKAL(G):
    A â† âˆ…
    sort G.E rosnÄ…co wg wagi
    make-set(u) for each u in G.V
    for each (u, v) in G.E do
        if FIND-SET(u) â‰  FIND-SET(v) then
            A.append((u, v))
            UNION(u, v)
    return A

```

## Kolorowanie wierzchoÅ‚kowe (Greedy)

**Opis:** ZachÅ‚annie nadaje najmniejszy moÅ¼liwy kolor kolejnym wierzchoÅ‚kom.  
**ZÅ‚oÅ¼onoÅ›Ä‡ czasowa:** O(V + E)  
**ZÅ‚oÅ¼onoÅ›Ä‡ pamiÄ™ciowa:** O(V)

```
GREEDY_VERTEX_COLOR(G):
    for each u in G.V in dowolnej kolejnoÅ›ci do
        forbidden â† { v.color | v in G.adj[u] }
        u.color â† smallest k not in forbidden

```

## Kolorowanie krawÄ™dziowe (Greedy)

**Opis:** ZachÅ‚annie nadaje najmniejszy moÅ¼liwy kolor kolejnym krawÄ™dziom, unikajÄ…c konfliktÃ³w na incydentnych krawÄ™dziach.  
**ZÅ‚oÅ¼onoÅ›Ä‡ czasowa:** O(E + V)  
**ZÅ‚oÅ¼onoÅ›Ä‡ pamiÄ™ciowa:** O(E)

```
GREEDY_EDGE_COLOR(G):
    for each edge e = (u, v) in G.E in dowolnej kolejnoÅ›ci do
        forbidden â† { e'.color | e' adjacent to u or v }
        e.color â† smallest k not in forbidden

```

22. NajwaÅ¼niejsze algorytmy wyznaczania otoczki wypukÅ‚ej zbioru punktÃ³w w ukÅ‚adzie wspÃ³Å‚rzÄ™dnych.

## 1. Co to jest â€algorytm wyznaczania otoczki wypukÅ‚ejâ€

Algorytm wyznaczania otoczki wypukÅ‚ej dla zbioru punktÃ³w w pÅ‚aszczyÅºnie to metoda znajdowania najmniejszego wielokÄ…ta wypukÅ‚ego, ktÃ³ry zawiera wszystkie te punkty.

- **Otoczka wypukÅ‚a** to zbiÃ³r punktÃ³w spoÅ›rÃ³d P, ktÃ³re tworzÄ… wierzchoÅ‚ki tego wielokÄ…ta.
    
- Wszystkie pozostaÅ‚e punkty leÅ¼Ä… wewnÄ…trz lub na krawÄ™dziach otrzymanego wielokÄ…ta.
    
- Zastosowania: grafika komputerowa, analiza ksztaÅ‚tÃ³w, obliczenia geometryczne.
    

---

## 2. Monotone Chain â€“ krok po kroku pseudokod

1. **WejÅ›cie**  
    â€¢ P â€“ lista n punktÃ³w (x, y)
    
2. **Sortowanie**
    
    1. Posortuj listÄ™ P rosnÄ…co po x, a przy rÃ³wnych x â€“ po y.
        
3. **Budowa dolnej otoczki (L)**
    
    1. UtwÃ³rz pustÄ… listÄ™ L.
        
    2. Dla kaÅ¼dego punktu p z posortowanego P, kolejno:  
        a. DopÃ³ki |L| â‰¥ 2 i orientacja(L[-2], L[-1], p) â‰¤ 0, usuÅ„ ostatni element z L.  
        b. Dodaj p na koniec L.
        
4. **Budowa gÃ³rnej otoczki (U)**
    
    1. UtwÃ³rz pustÄ… listÄ™ U.
        
    2. Dla kaÅ¼dego punktu p z posortowanego P w odwrotnej kolejnoÅ›ci:  
        a. DopÃ³ki |U| â‰¥ 2 i orientacja(U[-2], U[-1], p) â‰¤ 0, usuÅ„ ostatni element z U.  
        b. Dodaj p na koniec U.
        
5. **Scalanie obu Å‚aÅ„cuchÃ³w**
    
    1. UsuÅ„ ostatni punkt z L i ostatni punkt z U (bo sÄ… takie same jak punkty startowe).
        
    2. OtrzymanÄ… otoczkÄ™ wypukÅ‚Ä… H uzyskasz przez poÅ‚Ä…czenie L i U w tej kolejnoÅ›ci:  
        â€¢ H â† L concatenated with U
        
6. **WyjÅ›cie**  
    â€¢ H â€“ lista punktÃ³w w kolejnoÅ›ci zgodnej z obwodem otoczki (zwraca punkty wierzchoÅ‚kowe).
    

---

### Funkcja pomocnicza

- **orientacja(a, b, c)**  
    Oblicza wartoÅ›Ä‡ wyznacznika:
    
    orient = (b.x â€“ a.x)Â·(c.y â€“ a.y) â€“ (b.y â€“ a.y)Â·(c.x â€“ a.x)  
    â€¢ > 0 â†’ zakrÄ™t w lewo  
    â€¢ < 0 â†’ zakrÄ™t w prawo  
    â€¢ = 0 â†’ punkty wspÃ³Å‚liniowe
    

---

> **ZÅ‚oÅ¼onoÅ›Ä‡ czasowa:**  
> â€¢ Sortowanie: O(n log n)  
> â€¢ Budowa obu Å‚aÅ„cuchÃ³w: O(n)  
> **ÅÄ…cznie:** O(n log n)
> 
> **PamiÄ™ciowa:** O(n) (listy L, U i posortowane P)


23. JÄ™zyki regularne: warunki rÃ³wnowaÅ¼ne definicji- automat, prawa kongruencja, syntaktyczna, wyraÅ¼enia regularne. Lemat o pompowaniu kolegi.
## Definicje rÃ³wnowaÅ¼ne jÄ™zykÃ³w regularnych

### 1. Automat skoÅ„czony (DFA/NFA)

- **Deterministyczny automat skoÅ„czony (DFA)**  
    â€“ piÄ™ciotuple \ (Q, Î£, Î´, qâ‚€, F)\ , gdzie  
    â€¢ Q â€“ skoÅ„czony zbiÃ³r stanÃ³w  
    â€¢ Î£ â€“ alfabet wejÅ›ciowy  
    â€¢ Î´ : Q Ã— Î£ â†’ Q â€“ funkcja przejÅ›cia  
    â€¢ qâ‚€ âˆˆ Q â€“ stan startowy  
    â€¢ F âŠ† Q â€“ stany akceptujÄ…ce  
    â€“ akceptuje sÅ‚owo w âˆˆ Î£* â‡” po przetworzeniu w pozostaje w stanie q âˆˆ F.
    
- **Niedeterministyczny automat skoÅ„czony (NFA)**  
    â€“ podobnie, ale Î´ : Q Ã— (Î£ âˆª {Îµ}) â†’ P(Q)  
    â€“ zezwala na przejÅ›cia Îµ i ma wiele moÅ¼liwych stanÃ³w  
    â€“ DFA i NFA rozpoznajÄ… dokÅ‚adnie te same jÄ™zyki.
    

---

### 2. WyraÅ¼enia regularne

- **SkÅ‚adnia**
    
    1. âˆ… i Îµ sÄ… wyraÅ¼eniami regularnymi.
        
    2. JeÅ›li a âˆˆ Î£, to a jest wyraÅ¼eniem regularnym.
        
    3. JeÅ›li R, S sÄ… wyraÅ¼eniami, to  
        â€¢ (R â‹ƒ S) â€“ alternacja,  
        â€¢ (RÂ·S) â€“ konkatenacja,  
        â€¢ (R)* â€“ iteracja (Kleene)  
        sÄ… wyraÅ¼eniami regularnymi.
        
- **Semantyka**  
    â€“ KaÅ¼de wyraÅ¼enie R definiuje jÄ™zyk L(R) âŠ† Î£* zgodnie z konstrukcjami:  
    â€¢ L(âˆ…) = âˆ…, L(Îµ) = {Îµ}, L(a) = {â€œaâ€}  
    â€¢ L(R â‹ƒ S) = L(R) âˆª L(S)  
    â€¢ L(RÂ·S) = { xy | x âˆˆ L(R), y âˆˆ L(S) }  
    â€¢ L(R*) = â‹ƒ_{kâ‰¥0} L(R)^k
    

---

### 3. Kongruencja syntaktyczna (Myhill-Nerode)

- **Relacja rÃ³wnowaÅ¼noÅ›ci â‰¡â‚—** na Î£*:  
    dla x,y âˆˆ Î£* mamy x â‰¡â‚— y â‡” âˆ€z âˆˆ Î£*: xz âˆˆ L â‡” yz âˆˆ L
    
- **Twierdzenie Myhilla-Nerode**  
    L jest regularny â‡” â‰¡â‚— ma skoÅ„czenie wiele klas rÃ³wnowaÅ¼noÅ›ci.
    
- **Wniosek**  
    â€¢ Minimalny DFA dla L ma liczbÄ™ stanÃ³w rÃ³wnÄ… liczbie klas â‰¡â‚—.
    

---

## Lemat o pompowaniu dla jÄ™zykÃ³w regularnych

1. **Twierdzenie**  
    JeÅ›li L âŠ† Î£* jest nieskoÅ„czonym jÄ™zykiem regularnym, to istnieje liczba p â‰¥ 1 (tzw. dÅ‚ugoÅ›Ä‡ pompowania) taka, Å¼e  
    dla kaÅ¼dego w âˆˆ L z |w| â‰¥ p istnieje rozkÅ‚ad  
    w = xyz  
    speÅ‚niajÄ…cy:
    
    - |xy| â‰¤ p
        
    - |y| â‰¥ 1
        
    - âˆ€k â‰¥ 0: x y^k z âˆˆ L
        
2. **Interpretacja**  
    â€“ SÅ‚owo w o dÅ‚ugoÅ›ci â‰¥ p po przejÅ›ciu przez p+1 stanÃ³w DFA musi odwiedziÄ‡ co najmniej jeden stan dwukrotnie â†’ tam moÅ¼na â€pompowaÄ‡â€ fragment y.
    
3. **Zastosowanie**  
    â€“ Aby pokazaÄ‡, Å¼e jÄ™zyk M nie jest regularny, zaÅ‚Ã³Å¼, Å¼e jest, wybierz p i sprÃ³buj znaleÅºÄ‡ w âˆˆ M, |w| â‰¥ p, takie Å¼e dla dowolnego rozkÅ‚adu xyz z warunkami powyÅ¼ej istnieje k, dla ktÃ³rego x y^k z âˆ‰ M.
    
4. **PrzykÅ‚ad dowodu nieregularnoÅ›ci**
    
    - L = { aâ¿bâ¿ | n â‰¥ 0 }
        
    - ZaÅ‚Ã³Å¼ p; wybierz w = a^p b^p
        
    - KaÅ¼dy rozkÅ‚ad xyz z |xy| â‰¤ p â‡’ y = a^m dla m â‰¥ 1
        
    - Dla k=2: x y^2 z = a^{p+m} b^p ma wiÄ™cej a niÅ¼ b, wiÄ™c âˆ‰ L â‡’ sprzecznoÅ›Ä‡.
        

---

## Podsumowanie

- **Automaty**, **wyraÅ¼enia regularne** i **klasy â‰¡â‚—** to trzy rÃ³wnowaÅ¼ne definicje jÄ™zykÃ³w regularnych.
    
- **Lemat o pompowaniu** pozwala wykazaÄ‡ nieregularnoÅ›Ä‡ jÄ™zyka poprzez przeciwdowÃ³d.
    
21.Automat minimalny, wybrany algorytm minimalizacji. Automaty deterministyczne i niedeterministyczne (w tym ze stosem); determinizacja.
## Minimalny automat (DFA)

**Opis:**  
Minimalny DFA to najmniejszy (najmniejsza liczba stanÃ³w) deterministyczny automat rozpoznajÄ…cy ten sam jÄ™zyk co dany DFA. Opiera siÄ™ na Å‚Ä…czeniu rÃ³wnowaÅ¼nych stanÃ³w (Myhill-Nerode).

**ZÅ‚oÅ¼onoÅ›Ä‡ czasowa:** O(n log n) (Hopcroft)  
**ZÅ‚oÅ¼onoÅ›Ä‡ pamiÄ™ciowa:** O(n + m) (n stanÃ³w, m przejÅ›Ä‡)

```pseudocode
HOPCROFT-Minimize(DFA):
    P â† {F, Q \ F}          # podziaÅ‚ na akceptujÄ…ce i nieakceptujÄ…ce
    W â† {F, Q \ F}
    while W â‰  âˆ… do
        A â† any set from W
        remove A from W
        for each symbol c in Î£ do
            X â† { q | Î´(q, c) âˆˆ A }
            for each Y in P do
                Y1 â† X âˆ© Y
                Y2 â† Y \ X
                if Y1 â‰  âˆ… and Y2 â‰  âˆ… then
                    replace Y in P by Y1, Y2
                    if Y in W then
                        replace Y in W by Y1, Y2
                    else
                        add smaller of {Y1, Y2} to W
    construct new DFA from blocks in P
```

## Problemy rozstrzygalne i nierozstrzygalne w teorii jÄ™zykÃ³w

### 1. Problemy rozstrzygalne  
â€“ istnieje algorytm Turinga, ktÃ³ry zawsze zatrzymuje siÄ™ i poprawnie odpowiada TAK/NIE.  
- **PrzynaleÅ¼noÅ›Ä‡ (membership)**  
  - ReguÅ‚ regularnych (DFA/NFA): O(n)  
  - Gramatyk kontekstowo-wolnych (CYK): O(nÂ³)  
- **Pusty jÄ™zyk (emptiness)**  
  - Dla DFA/NFA i CFG: decyduje siÄ™ w czasie wielomianowym  
- **Finiteness (skoÅ„czonoÅ›Ä‡ jÄ™zyka)**  
  - Dla DFA/NFA i CFG: wielomianowo  
- **Inkluzja i rÃ³wnowaÅ¼noÅ›Ä‡**  
  - Dla regularnych: decyzyjne (poprzez minimalizacjÄ™ i porÃ³wnanie DFA)  
  - Dla CFG: **nierozstrzygalne**  

### 2. Problemy nierozstrzygalne  
â€“ nie istnieje algorytm, ktÃ³ry dla wszystkich instancji zatrzyma siÄ™ z poprawnÄ… odpowiedziÄ….  
- **Problem stopu (Halting Problem)** dla maszyn Turinga  
- **Problem rÃ³wnowaÅ¼noÅ›ci CFG**: czy L(Gâ‚)=L(Gâ‚‚)?  
- **Problem inkluzji CFG**: czy L(Gâ‚)âŠ†L(Gâ‚‚)?  
- **Post Correspondence Problem (PCP)**  

---
25.
## Klasy zÅ‚oÅ¼onoÅ›ci P, NP, NP-zupeÅ‚ne

### P  
**Opis:** decyzje rozwiÄ…zywane deterministycznie w czasie wielomianowym.  
**Definicja:**  
> P = { L | âˆƒ deterministyczna maszyna Turinga M i wielomian p(n) takie, Å¼e M decyduje L w czasie O(p(n)) }  
**PrzykÅ‚ady:** przeszukiwanie BFS/DFS, mnoÅ¼enie macierzy, sortowanie przeglÄ…dane, sprawdzanie przynaleÅ¼noÅ›ci w DFA.

### NP  
**Opis:** problemy, dla ktÃ³rych â€TAKâ€ moÅ¼na zweryfikowaÄ‡ w czasie wielomianowym przy uÅ¼yciu dowodu (certyfikatu).  
**Definicja:**  
> NP = { L | âˆƒ niedeterministyczna maszyna Turinga M dziaÅ‚ajÄ…ca w czasie wielomianowym, ktÃ³ra akceptuje L }  
â€“ rÃ³wnowaÅ¼nie: âˆƒ deterministyczna maszyna weryfikujÄ…ca certyfikat w wielomianowym czasie.  
**PrzykÅ‚ady:** SAT, CLIQUE, Hamiltonian Path.

### NP-zupeÅ‚ne  
**Opis:** najtrudniejsze problemy w NP; kaÅ¼dy problem z NP moÅ¼na zredukowaÄ‡ do nich w czasie wielomianowym.  
**Definicja:** L jest NP-zupeÅ‚ne â‡”  
1. L âˆˆ NP  
2. âˆ€ L' âˆˆ NP: L' â‰¤â‚š L (wielomianowa redukcja)  
**PrzykÅ‚ady:** SAT (Twierdzenie Cooka), 3-SAT, Vertex Cover, Traveling Salesman Decision.

---

## ZaleÅ¼noÅ›ci miÄ™dzy klasami

- P âŠ† NP âŠ† PSPACE âŠ† â€¦  
- JeÅ›li âˆƒ choÄ‡ jeden NP-zupeÅ‚ny algorytm w P â‡” P = NP.  
- Hipoteza P â‰  NP â‡” P jest Å›ciÅ›le mniejsze od NP.

---

## Hipoteza P vs NP

- **Pytanie otwarte:** Czy kaÅ¼dy problem, ktÃ³rego rozwiÄ…zanie da siÄ™ zweryfikowaÄ‡ w czasie wielomianowym, da siÄ™ teÅ¼ rozwiÄ…zaÄ‡ w czasie wielomianowym?  
- **Implikacje:**  
  - P = NP â†’ wiÄ™kszoÅ›Ä‡ problemÃ³w kombinatorycznych miaÅ‚aby efektywne rozwiÄ…zania  
  - P â‰  NP â†’ sÄ… problemy w NP, ktÃ³rych nie da siÄ™ rozwiÄ…zaÄ‡ szybciej niÅ¼ w czasie wykÅ‚adniczym  
- **Status:** nierozstrzygniÄ™te od 1971; jedno z najwaÅ¼niejszych pytaÅ„ w informatyce teoretycznej i matematyce.  


26. Chomsky
## Hierarchia Chomskyâ€™ego

- **Typ 0** (rekurencyjnie przeliczalne)  
    â€“ akceptowane przez niedeterministycznÄ… maszynÄ™ Turinga.
    
- **Typ 1** (kontekstowo-wraÅ¼liwe)  
    â€“ akceptowane przez liniowo ograniczone PDA (LBA).
    
- **Typ 2** (bezkontekstowe)  
    â€“ akceptowane przez niedeterministyczne PDA.
    
- **Typ 3** (regularne)  
    â€“ akceptowane przez DFA/NFA lub opisane wyraÅ¼eniami regularnymi.
    

---

## ZamkniÄ™toÅ›Ä‡ klas jÄ™zykÃ³w

### Typ 3: jÄ™zyki regularne

**Operacje boolowskie**

- suma (âˆª): âœ“
    
- przekrÃ³j (âˆ©): âœ“
    
- dopeÅ‚nienie: âœ“
    
- rÃ³Å¼nica: âœ“
    

**Inne operacje**

- konkatenacja: âœ“
    
- gwiazdka Kleene (L*): âœ“
    
- homomorfizm: âœ“
    
- odwrotny homomorfizm: âœ“
    
- substytucja: âœ“
    
- odwrÃ³cenie (reversal): âœ“
    
- iloraz lewostronny/prawo (Lâˆ•R): âœ“
    

---

### Typ 2: jÄ™zyki bezkontekstowe

**Operacje boolowskie**

- suma (âˆª): âœ“
    
- przekrÃ³j (âˆ©) z dowolnym CF: âœ—
    
- przekrÃ³j (âˆ©) z regularnym: âœ“
    
- dopeÅ‚nienie: âœ—
    
- rÃ³Å¼nica: âœ—
    

**Inne operacje**

- konkatenacja: âœ“
    
- gwiazdka Kleene (L*): âœ“
    
- homomorfizm: âœ“
    
- odwrotny homomorfizm: âœ“
    
- substytucja: âœ“
    
- odwrÃ³cenie (reversal): âœ“
    
- iloraz przez regularny (Lâˆ•R, Râˆ–L): âœ“
    

---

### Typ 1: jÄ™zyki kontekstowo-wraÅ¼liwe

**Operacje boolowskie**

- suma (âˆª): âœ“
    
- przekrÃ³j (âˆ©): âœ“
    
- dopeÅ‚nienie: âœ“
    
- rÃ³Å¼nica: âœ“
    

**Inne operacje**

- konkatenacja: âœ“
    
- gwiazdka Kleene (L*): âœ“
    
- homomorfizm (nie-kasujÄ…cy): âœ“
    
- odwrotny homomorfizm: âœ“
    
- substytucja (z jÄ™zykami CS): âœ“
    
- odwrÃ³cenie (reversal): âœ“
    
- iloraz lewostronny/prawo: âœ“
    

---

### Typ 0: jÄ™zyki rekurencyjnie przeliczalne

**Operacje boolowskie**

- suma (âˆª): âœ“
    
- przekrÃ³j (âˆ©): âœ“
    
- dopeÅ‚nienie: âœ—
    
- rÃ³Å¼nica: âœ—
    

**Inne operacje**

- konkatenacja: âœ“
    
- gwiazdka Kleene (L*): âœ“
    
- homomorfizm: âœ“
    
- odwrotny homomorfizm: âœ“
    
- substytucja: âœ“
    
- odwrÃ³cenie (reversal): âœ“
    
- iloraz lewostronny/prawo: âœ“
    

---

**Uwagi:**

- â€âœ—â€ oznacza brak zamkniÄ™cia w ogÃ³lnoÅ›ci (moÅ¼liwe wyjÄ…tki przy dodatkowych ograniczeniach).
    
- dla CF i CS niektÃ³re operacje (np. przekrÃ³j) stajÄ… siÄ™ zamkniÄ™te, gdy jeden operand jest z klasy niÅ¼szej (zwykle regularnej).